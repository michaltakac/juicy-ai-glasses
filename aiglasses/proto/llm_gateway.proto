syntax = "proto3";

package aiglasses.llm_gateway;

import "common.proto";

option python_package = "aiglasses.proto.llm_gateway";

// LLM Gateway Service - broker to LAN/cloud LLM providers
service LLMGatewayService {
  // Health check
  rpc GetHealth(aiglasses.common.Empty) returns (aiglasses.common.HealthResponse);
  
  // Get gateway status
  rpc GetStatus(aiglasses.common.Empty) returns (GatewayStatus);
  
  // Chat completion (streaming)
  rpc Chat(ChatRequest) returns (stream ChatResponse);
  
  // Chat completion (non-streaming)
  rpc ChatComplete(ChatRequest) returns (ChatCompleteResponse);
  
  // List available providers
  rpc ListProviders(aiglasses.common.Empty) returns (ProviderList);
  
  // Test provider connectivity
  rpc TestProvider(TestProviderRequest) returns (TestProviderResponse);
  
  // Configure gateway
  rpc Configure(GatewayConfig) returns (ConfigureResponse);
  
  // Get usage metrics
  rpc GetUsage(UsageRequest) returns (UsageResponse);
}

message GatewayStatus {
  bool available = 1;
  string active_provider = 2;
  repeated ProviderStatus providers = 3;
  string error_message = 4;
  GatewayMetrics metrics = 5;
}

message ProviderStatus {
  string id = 1;
  string name = 2;
  string type = 3;  // "lan", "openai", "anthropic", "ollama"
  bool available = 4;
  bool configured = 5;
  int64 latency_ms = 6;  // Last measured latency
  string error = 7;
}

message GatewayMetrics {
  int64 total_requests = 1;
  int64 total_tokens = 2;
  float avg_latency_ms = 3;
  int64 errors = 4;
}

message ChatRequest {
  repeated Message messages = 1;
  string model = 2;  // Empty = use default
  string provider = 3;  // Empty = use active provider
  float temperature = 4;  // 0.0-2.0, default 0.7
  int32 max_tokens = 5;  // Default 1024
  bool stream = 6;  // Default true for Chat(), ignored for ChatComplete
  repeated Tool tools = 7;  // Available tools for function calling
  string system_prompt = 8;  // Override system prompt
}

message Message {
  string role = 1;  // "system", "user", "assistant", "tool"
  string content = 2;
  string name = 3;  // For tool messages
  repeated ToolCall tool_calls = 4;  // For assistant messages with tool use
  string tool_call_id = 5;  // For tool response messages
}

message Tool {
  string name = 1;
  string description = 2;
  string parameters_schema = 3;  // JSON Schema
}

message ToolCall {
  string id = 1;
  string name = 2;
  string arguments = 3;  // JSON string
}

message ChatResponse {
  string content = 1;
  bool done = 2;
  string finish_reason = 3;  // "stop", "length", "tool_calls"
  repeated ToolCall tool_calls = 4;
  Usage usage = 5;  // Only on final message
  int64 latency_ms = 6;
}

message ChatCompleteResponse {
  Message message = 1;
  string finish_reason = 2;
  Usage usage = 3;
  int64 latency_ms = 4;
  string provider_used = 5;
  string model_used = 6;
}

message Usage {
  int32 prompt_tokens = 1;
  int32 completion_tokens = 2;
  int32 total_tokens = 3;
}

message ProviderList {
  repeated ProviderInfo providers = 1;
}

message ProviderInfo {
  string id = 1;
  string name = 2;
  string type = 3;
  string endpoint = 4;
  repeated string available_models = 5;
  string default_model = 6;
  bool requires_api_key = 7;
  bool configured = 8;
}

message TestProviderRequest {
  string provider_id = 1;
}

message TestProviderResponse {
  bool success = 1;
  int64 latency_ms = 2;
  string message = 3;
  string model_tested = 4;
}

message GatewayConfig {
  string active_provider = 1;
  string default_model = 2;
  float default_temperature = 3;
  int32 default_max_tokens = 4;
  int32 timeout_seconds = 5;
  int32 retry_count = 6;
  string fallback_provider = 7;
}

message ConfigureResponse {
  bool success = 1;
  string message = 2;
}

message UsageRequest {
  string start_date = 1;  // ISO date
  string end_date = 2;
  string provider = 3;  // Empty = all
}

message UsageResponse {
  int64 total_requests = 1;
  int64 total_tokens = 2;
  int64 prompt_tokens = 3;
  int64 completion_tokens = 4;
  map<string, int64> tokens_by_provider = 5;
  map<string, int64> requests_by_provider = 6;
}


